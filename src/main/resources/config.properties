# zookeeper parameters
zookeeper.connect=127.0.0.1:2181
#zookeeper.session.timeout.ms=400
#zookeeper.sync.time.ms=200
 
# kafka parameters
kafka.group.id= hdfssink
kafka.topic=testavro

# number of parallel kafka consumers to run
consumer.threads=4

# implementation class to process messages
adapter.message.processor=com.ligadata.adapters.hdfs.BufferedPartitionedAvroSink

# uri to create files under
hdfs.uri=file:/tmp/data/instrumentationlog

# prefix to name all files created under above uri
file.prefix=AppLog

# can be deflate, snappy, bzip2, xz
# if not given, no compression is used
file.compression=bzip2

# SimpleDateFormat format string used to parse date in input message
input.date.format=yyyy-MM-dd

# partition messages using these comma separated ordered list of attributes
# format: attributename1,attributename2,..
# attribute names should match schema definition.
# optional SimpleDateFormat format string can be used after ":" for date attributes 
file.partition.strategy=timestamp:yyyy,timestamp:MM,timestamp:dd

# Avro schema file location
schema.file=src/main/resources/InstrumentationLog.avsc

# jdbc connection
jdbc.driver=com.microsoft.sqlserver.jdbc.SQLServerDriver
#jdbc.url=ec2-54-160-245-36.compute-1.amazonaws.com
jdbc.url=jdbc:sqlserver://ec2-54-160-245-36.compute-1.amazonaws.com:1433;databaseName=admin;
jdbc.port=1433
jdbc.database=admin
jdbc.schema=dbo
jdbc.table=COPS
jdbc.user=admin
jdbc.password=pass123
jdbc.insert.statement=

# parameters to control message batching
# messages will be written every "count" messages or every "interval" seconds
sync.messages.count=10
sync.interval.seconds=120
